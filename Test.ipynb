{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Config import parse_arguments\n",
    "from Models.model_utils import FEDMD_digest_revisit, save_checkpoints, select_model, get_logits, create_model_architectures_noblip\n",
    "from Common.dataset_fedmd import FEDMD_load_dataloaders_noblip, FEDMD_load_datasets_noblip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(sample_fraction=1.0, min_num_clients=2, KD=False, algo_type='FEDMD_homogen', available_architectures_noblip=['NetS', 'DeepNN_Ram', 'DeepNN_Hanu', 'DeepNN_Lax'], available_architectures_blip=['MLP1', 'MLP2', 'MLP3', 'MLP4'], name='cifar100', partitioning='dirichlet', num_clients=10, num_rounds=20, BLIP=False, proximal_mu=0.02, scheduler_=False, val_ratio=0.2, seed=42, alpha=1.0, labels_per_client=2, similarity=0.5, batch_size=32, batch_size_ratio=0.01, server_epochs=5, num_cpus=1, num_gpus=1, device='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\"\"\"\n",
    "\n",
    "    config = {\n",
    "        \"server_round\": server_round,\n",
    "        \"epochs\": 2,\n",
    "        \"proximal_mu\":args.proximal_mu,\n",
    "        \"client_kd_alpha\": 0.3,\n",
    "        \"client_kd_temperature\": 3,\n",
    "        \"server_kd_alpha\": 0.7,\n",
    "        \"server_kd_temperature\": 7,\n",
    "        \"server_lr\": 0.001 \n",
    "            }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def trasfer_learning_init(args, model_architectures, serverloader, trainloaders):\n",
    "    \"\"\"\n",
    "    Initialize the model for transfer learning.\n",
    "    This function trains the model on the server data and then initializes client models.\n",
    "    \"\"\"\n",
    "\n",
    "    client_logits = {}\n",
    "    config = fit_config(server_round=0)\n",
    "    num_classes=100\n",
    "\n",
    "    for i, trainloader in enumerate(trainloaders):\n",
    "        print(f\"\\n Transfer learning on client {i + 1}\\n\")\n",
    "\n",
    "        net = select_model(model_architectures[i], args.device, args.BLIP, num_classes=num_classes)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "        # Training the model on public data\n",
    "        FEDMD_digest_revisit(serverloader, net, optimizer, args.device, config, aggregated_logits=None, mode=\"revisit\")\n",
    "        # Training the model on private data\n",
    "        FEDMD_digest_revisit(trainloader, net, optimizer, args.device, config, aggregated_logits=None, mode=\"revisit\")\n",
    "        # logit Communication for round 1\n",
    "        client_logits[i] = get_logits(serverloader, net, args.device)\n",
    "        # Save the model and optimizer state for each client\n",
    "        checkpoint_dir = f\"client_checkpoints/{args.algo_type}/{args.alpha}/client_{i}\"\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        save_checkpoints(net, optimizer, 0, checkpoint_dir)\n",
    "\n",
    "    logits = np.vstack([client_logits[i] for i in sorted(client_logits.keys())])\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloaders, valloaders, testloader, server_loader = FEDMD_load_dataloaders_noblip(args)\n",
    "results_save_path = f\"./results/NO_BLIP/{args.algo_type}/{args.alpha}\"\n",
    "model_architectures = create_model_architectures_noblip(args.available_architectures_noblip, args.algo_type, args.num_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0,2,20,63,71,82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from torch.utils.data import ConcatDataset, Dataset, Subset\n",
    "from torchvision.datasets import CIFAR10, MNIST, CIFAR100\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_CIFAR_data(data_type=\"CIFAR10\", label_mode=\"fine\", standardized=False, verbose=False):    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]) if standardized else transforms.ToTensor()\n",
    "\n",
    "    if data_type == \"CIFAR10\":\n",
    "        train_set = CIFAR10(root='./data/data_cifar10', train=True, download=True, transform=transform)\n",
    "        test_set = CIFAR10(root='./data/data_cifar10', train=False, download=True, transform=transform)\n",
    "        X_train, y_train = train_set.data, np.array(train_set.targets)\n",
    "        X_test, y_test = test_set.data, np.array(test_set.targets)\n",
    "    elif data_type == \"CIFAR100\":\n",
    "        train_set = CIFAR100(root='./data/data_cifar100', train=True, download=True, transform=transform)\n",
    "        test_set = CIFAR100(root='./data/data_cifar100', train=False, download=True, transform=transform)\n",
    "        X_train, y_train = train_set.data, np.array(train_set.targets)  # Fine labels by default\n",
    "        X_test, y_test = test_set.data, np.array(test_set.targets)\n",
    "        \n",
    "        if label_mode == \"coarse\":\n",
    "            # Use coarse labels instead of fine labels\n",
    "            y_train = np.array(train_set.coarse_targets)\n",
    "            y_test = np.array(test_set.coarse_targets)\n",
    "    else:\n",
    "        print(\"Unknown Data type. Stopped!\")\n",
    "        return None\n",
    "\n",
    "    if verbose:\n",
    "        print(\"X_train shape:\", X_train.shape)\n",
    "        print(\"X_test shape:\", X_test.shape)\n",
    "        print(\"y_train shape:\", y_train.shape)\n",
    "        print(\"y_test shape:\", y_test.shape)\n",
    "        if data_type == \"CIFAR100\":\n",
    "            print(f\"Using {label_mode} labels\")\n",
    "            print(\"Label distribution:\", np.unique(y_train, return_counts=True))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR100' object has no attribute 'coarse_targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_CIFAR_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCIFAR100\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoarse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstandardized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m, in \u001b[0;36mload_CIFAR_data\u001b[0;34m(data_type, label_mode, standardized, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m     X_test, y_test \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39mdata, np\u001b[38;5;241m.\u001b[39marray(test_set\u001b[38;5;241m.\u001b[39mtargets)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoarse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# Use coarse labels instead of fine labels\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m         y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoarse_targets\u001b[49m)\n\u001b[1;32m     26\u001b[0m         y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(test_set\u001b[38;5;241m.\u001b[39mcoarse_targets)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CIFAR100' object has no attribute 'coarse_targets'"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_CIFAR_data(data_type=\"CIFAR100\", label_mode=\"coarse\", standardized=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]) \n",
    "train_set = CIFAR100(root='./data/data_cifar100', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR100' object has no attribute 'coarse_targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoarse_targets\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CIFAR100' object has no attribute 'coarse_targets'"
     ]
    }
   ],
   "source": [
    "np.array(train_set.coarse_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blip-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
